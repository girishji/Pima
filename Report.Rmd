---
title: "Forecasting the Onset of Diabetes Milletus"
subtitle: "An application of binary choice models"
author: "Girish Palya (425998) and Karina Norvoish ()"
date: "`r Sys.Date()`"
output:
  tufte::tufte_html: default
  tufte::tufte_handout:
    citation_package: natbib
    latex_engine: xelatex
  tufte::tufte_book:
    citation_package: natbib
    latex_engine: xelatex
bibliography: skeleton.bib
link-citations: yes
---

```{r setup, include=FALSE}
library(tufte)
library(tidyverse)
library(knitr)
library(GGally)
# invalidate cache when the tufte version changes
knitr::opts_chunk$set(tidy = FALSE, cache.extra = packageVersion('tufte'))
options(htmltools.dir.version = FALSE)
```

# Abstract

Statistical methods have been used to help medical professionals make better diagnosis.
In this study we apply binomial choice models like logit and probit
to a data set from a population at high risk of the onset of diabetes. 
We analyze the performance of models using standard measures
for clinical tests: sensitivity, specificity, and a receiver operating
characteristic curve. A description of the models
is included.

# Introduction

[Diabetes mellitus](https://en.wikipedia.org/wiki/Diabetes), commonly 
known as diabetes, is a group of metabolic disorders characterized by 
a high blood sugar level over a prolonged period of time. It afflicts 
nearly 9% of world population (463 million) and causes 4 million 
deaths every year.

The ability to forecast is central to many medical situations. Standard statistical 
techniques such as discriminate
analysis, regression analysis, and factor analysis have been used to
provide this ability. Even though sophesticated neural network models have been
used
to predict the onset of diabetes using the same data set, we beleive
there is merit in using workhorse statistical models since sample size is
fairly large (768 observations) and underlying functional correlations
among variables can be evaluated and minimized. 

# Related Work

Smith et. al.^[JW Smith, JE Everhart, WC Dicksont,
WC Knowler, RS Johannes. 1988. *Using the ADAP Learning Algorithm to Forecast
the Onset of Diabetes Mellitus*] have used the ADAP Learning Algorithm to forecast
the onset of diabetes mellitus using the same data. 
They describe ADAP as "an adaptive learning routine that generates and executes
digital analogs of perceptron-like devices". 

> "ADAP was developed by two of the authors [Smith, Dickson] in 1961. We chose to examine the ADAP algorithm and test its use in forecasting the onset of non-insulin-dependent diabetes mellitus (DM) within a five-year period. The data used in this study were from the Pima Indian population near Phoenix, Arizona. Once the algorithm had been trained using 576 cases, ADAP was used to forecast whether another 192 test cases would develop diabetes within five years. Forcing ADAP to conclude on all test cases produced a sensitivity and specificity of 76 percent."


In diagnostic medicine, testing the hypothesis that the ROC Curve area or partial 
area has a specific value is a common practice^[*Statistical Methods in 
Diagnostic Medicine*, Second Edition, Ch.4,
Author(s): Xiao‚ÄêHua Zhou Nancy A. Obuchowski Donna K. McClish]. 

Although many sophisticated models have been developed for discriminant analysis, 
recent empirical comparisons indicate that standard methods such as 
logistic regression work very well^[C B Begg. *Statistical Methods in Medical Diagnosis*].

Our null hypothesis is that binary choice models like logit and probit
will produce as good a result as ADAP.

*H0: Crossover point for sensitivity and specificity for binary choice models is greater than 0.76.*

# Data

Data comes from [Kaggle](https://www.kaggle.com/uciml/pima-indians-diabetes-database) via UCI Machine Learning Repository.

```{r}
diabetes <- as_tibble(read.csv(url(str_c(
  "https://raw.githubusercontent.com/girishji/",
  "Pima/master/data/diabetes.csv"))))
diabetes[1:6, ] %>% kable(caption = 'A subset of data.')
```

## Study Population

The population for this study was the Pima Indian population near
Phoenix, Arizona. That population has been under continuous
study since 1965 by the 
[National Institute of Diabetes and Digestive and Kidney Diseases](https://www.niddk.nih.gov/) 
because of its high incidence rate
of diabetes. Each community resident over 5 years of age
was asked to undergo a standardized examination every two years,
which included an oral glucose tolerance test. Diabetes was
diagnosed according to 
World Health Organization Criteria^[World Health Organization, *Report of a Study Group: Diabetes Mellitus*. World Health Organization Technical
Report Series. Geneva, 727, 1985.];
that is, if the 2 hour post-load plasma glucose was at least 200
mg/dl (11.1 mmol/l) at any survey examination or if the 
[Indian Health Service Hospital](https://www.ihs.gov/) serving the 
community found a glucose
concentration of at least 200 mg/dl during the course of routine 
medical care^[Knowler, W.C., P.H. Bennett, RF. Hamman, and M.
Milier. 1978. *Diabetes incidence and prevalence in Pima
Indians: a 19-fold greater incidence than in Rochester*,
Minnesota. Am J Epidemiol 108:497-505.]. 
In addition to being a familiar database to the
investigators, this data set provided a well validated data resource
in which to explore prediction of the date of onset of diabetes in a
longitudinal manner.

## Variables

The subjects of the study are Pima Indian women over 21 years of age. 
The following explanatory variables are found to be the risk factors 
for diabetes among women.

1. `Pregnancies`: Number of times pregnant
2. `Glucose`: Plasma Glucose Concentration at 2 Hours in an Oral
Glucose Tolerance Test (GTIT)
3. `BloodPressure`: Diastolic Blood Pressure (mm Hg)
4. `SkinThickness`: Triceps Skin Fold Thickness (mm)
5. `Insulin`: 2-Hour Serum Insulin Uh/ml)
6. `BMI`: Body Mss Index (Weight in kg / (Height in in))
7. `DPF`^[Diabetes Pedigree Function was developed 
by Smith et. al.* to provide a measure of the expected 
genetic influence of affected and unaffected relatives on the 
subject's eventual diabetes
risk. It  uses information from parents, grandparents,
full and half siblings, full and half aunts and uncles, and first
cousins.]: Diabetes Pedigree Function 
`r margin_note("* JW Smith, JE Everhart, WC Dicksont, WC Knowler, RS Johannes. 1988. *Using the ADAP Learning Algorithm to Forecast the Onset of Diabetes Mellitus*")`
8. `Age`: Age (years)

The binary dependent variable (`Outcome`) describes 
the onset of non-insulin-dependent diabetes
mellitus (DM) within a five-year period. This variable is 1 if diagnosis 
is positive within five years, and 0 otherwise.

## Observations from Data

Preliminary examination of data reveals following:

- There are many spurious 0 values in data, especially in `Insulin` and
`SkinThickness`. These values skew the mean and cause excessive outliers. 
We assume these to be errors in data, and suitable remedies
will be employed to address the skew.

- There are 500 negative instances (65.1%)
of the regressand (`Outcome`), comapared to 258 positive instances (34.9%).
Since CDFs underlying binomial logit and probit
models differ most in the tails, and produce similar predicted probabilities
for non-extreme values^[Christopher Baum. *An Introduction to Modern Econometrics Using Stata*], it is likely that the results obtained from logit and probit models 
are going to be similar.

- From the density plot (after temporarily filtering out spurious zero 
values) we can observe that not all distributions are normal. Data is skewed
towards younger subjects. `Pregnancies` are also skewed towards fewer pregnancies.
`BMI`, `Insulin`, and `SkinThickness` have long tails on the right side.



```{r echo=F}
diabetes %>%
  summarise_each(~ sum(.x == 0)) %>%
  pivot_longer(everything(), names_to = ' ',
               values_to = 'Count of Zero Values') %>%
  kable(caption = 'Zeros in some variables are errors in data.')
```

$\\$

```{r fig.cap = "Box plot showing spurious outliers in `Insulin` and `SkinThickness`, and skewed mean.", cache=TRUE, echo = F}
diabetes %>% 
  select(-Outcome) %>% 
  pivot_longer(everything(), names_to = 'Variable', 
               values_to = 'Value') %>% 
  ggplot(aes(x = Variable, y = Value, fill = Variable)) +
  geom_jitter(size=0.1, alpha=0.2) +
  stat_summary(fun=mean, geom="point", shape=20, size=4, color="red", fill="red") +
  geom_boxplot(alpha = 0.3) +
  theme(legend.position="none") +
  xlab("") +
  ylab('')
```


```{r fig.cap = "Density plot of regressors (without spurious zero values).", cache=TRUE, echo=F, fig.height=3}
diabetes %>% 
  select(-Outcome) %>% 
  pivot_longer(everything(), names_to='Regressor', 
               values_to='Value') %>% 
  # Filter out spurious zeroes
  filter(Regressor == 'Pregnancies' | Value != 0) %>% 
  ggplot(aes(x = Value, group = Regressor, 
             fill = Regressor)) +
  geom_density(alpha = 0.3) +
  facet_wrap(~Regressor, scales = "free", nrow = 2) +
  theme(legend.position="none") +
  xlab('') +
  ylab('')
```




```{r fig.cap = "Correlation among regressors.", cache=TRUE, fig.margin = TRUE, echo = F}
diabetes %>% 
  ggcorr(method = c("everything", "pearson"))
```

Examining the scatter plots and correlations among the variables reveals the following:

- Among all the regressors, `Glucose` concentration has the highest correlation (.467) with onset of diabetes.

- `Age` is not strongly correlated (.238) with the onset of diabetes. This seems to suggest that, either accumulation of unhealthy lifestyle habits is not a factor, or that such factors have already expressed themselves by the age of 21 years.

- Diabetes Pedigree Function (`DPF`) is not highly correlated with onset of diabetes, which suggests that hereditory factors may be less important.

- `Insulin` and `SkinThickness` show significant correlation (.437), but this maybe a result of both variables having too many spurios zero values.

- Presence of spurious zero values in `Insulin` could be masking its correlation with `Glucose`.

- None of the explanatory variables are strongly correlated with the response variable.

```{r fig.cap = "Correlation matrix of regressors.", cache=TRUE, echo=FALSE}
diabetes %>% 
  ggpairs(., lower = list(continuous = 
                            wrap("points", alpha = 0.3, 
                                 size = 0.1)))
```

# Method

Hello Matija
You should use a Zero-inflated regression model for both the Poisson regression and the Negative binomial regression. These models have two components: i) For explaining the excess of zeros and ii) for explaining the count data.
In the Stata software the commands are "zip" and "zinb".
You should do a diagnostic test in order to select the adequate regression model.
Good luck.
Andr√©s.

-

You are focusing on zeros as part of the distributions of several predictors, but the central questions for modelling include (a) what kind of response variable you have and (b) what kind of relationship you expect between the response and the predictors or explanatory variables.

Zeros in the predictors themselves rule out little except straight logarithmic transformation.

From your description, the starting point is that price is the response and prices are necessarily positive. That suggests immediately a regression model with log link and quite possibly Poisson regression. (The fact that price is not a count is secondary here. See for example http://blog.stata.com/tag/poisson-regression/ and its literature for explanation.)

From that, how to represent your predictors depends on their relationship with the response as much as, or more than, their marginal distributions. Your post supplies no information to guide advice, but I'd start with including them as they come and then consider if you need other representations, e.g. as roots, squares, set of indicator variables.





To begin, several predictors of the variable with missing values are identified using a correlation matrix. The best predictors are selected and used as independent variables in a regression equation. 





Although many sophisticated models have been developed for discriminant analysis, recent empirical comparisons indicate that standard methods such as linear discrimination and logistic regression work very well. More research is needed to overcome practical difficulties that are not accommodated in the conventional assumptions. Research on the assessment of diagnostic tests has been oriented more toward selection biases and practical problems. 

# Model

# Results

# Findings

















